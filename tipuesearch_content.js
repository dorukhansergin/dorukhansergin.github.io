var tipuesearch = {"pages":[{"url":"/about/","title":"About","tags":"blog","text":"About This Blog My name is Dorukhan and I'm a graduate student at Arizona State University, working towards to get a PhD in Industrial Engineering. I started this blog, mostly as a sophisticated brain dump, but also as to connect with the wider web. I've learned so much from other people's blog (sometimes more than the papers) that I felt the need to contribute myself. I hope my humble scribblings help someone understand and do things better.","loc":"/about/"},{"url":"/blog/2019/08/28/implementing-robust-pca-in-python/","title":"Implementing Robust PCA in Python","tags":"research","text":"In a previous post , I introduce robust PCA , the math behind and an example where I put the model in action. This post I will share my Python implementation of robust PCA . If you don't have any background in convex optimization, some of the discussions here might be boring or irrelevant. If you really just need an implementation of robust PCA , skip the background section and you'll find the code below. First Some Background Alternating Direction Method of Multipliers Say you have a convex optimization problem that looks like this: $$ \\begin{equation*} \\begin{aligned} & \\min_{X, Z} & & f(X) + g(Z) \\\\ & \\text{subject to} & & AX + BZ = C \\\\\\end{aligned}\\end{equation*} $$ where \\(f\\) and \\(g\\) are convex. The augmented Lagrangian looks like this: $$ \\mathcal{L}(X, Z, Y) = f(X) + g(Z) + \\langle Y,C-AX-BZ\\rangle + \\frac{\\mu}{2}\\|C-AX-BZ\\|_F&#94;2 $$ If you feel the need to understand how we got here, I suggest reading the second chapter of Boyd et al ‘s classic report on this. ADMM propses an iterative approach using the Lagrangian. Say we are at iteration \\(k\\) and we are given from previous iteration \\(X&#94;k\\) , \\(Z&#94;k\\) , \\(Y&#94;k\\) . The required iterations for step \\(k+1\\) will become: $$ \\begin{aligned} X&#94;{k+1} &= \\underset{X}{\\mathrm{argmin}}\\mathcal{L}(X, Z&#94;k, Y&#94;k) \\\\ Z&#94;{k+1} &= \\underset{Z}{\\mathrm{argmin}}\\mathcal{L}(X&#94;{k+1}, Z, Y&#94;k) \\\\ Y&#94;{k+1} &= Y&#94;k + \\mu(C-AX&#94;{k+1}-BZ&#94;{k+1}) \\end{aligned} $$ If you have a closed form solution for the updates of \\(X&#94;{k+1}\\) and \\(Z&#94;{k+1}\\) , you're in good luck. ADMM can be thought of as a tug-of-war between optimality gap and feasibility of the primal problem. This can be used to set up a systematic way to early stop the algorithm and/or play around with \\(\\mu\\) over iterations. According to Boyd et al , the primal residual and dual residuals of the problem can be quantified as \\(r&#94;k = \\|AX&#94;k-BZ&#94;k-C\\|_F&#94;2\\) and \\(h&#94;k = \\|\\mu_k A&#94;\\top B(Z&#94;k - Z&#94;{k+1})\\|_F&#94;2\\) , respectively. Algorithm can be terminated when both of these quantities are below a certain tolerance and advise on choosing these tolerance values also mentioned in the same report. To bias the algorithm towards reaching primal feasibility one can dial up \\(\\mu\\) (thus increasing the penalty on primal residuals) or dial it down for speeding up closing the optimality gap. The \\(\\mu_k\\) update then becomes: $$ \\mu_{k+1} = \\begin{cases} \\rho\\mu_k & \\text{if } r&#94;k > \\tau s&#94;k \\\\ \\mu_k\\mathbin{/}\\rho & \\text{if } s&#94;k > \\tau r&#94;k \\\\ \\mu_k & \\text{o.w.} \\end{cases} $$ This gives us an almost complete look at ADMM . Now we will see how we can write a special case of ADMM for robust PCA . Robust PCA via ADMM Let's refresh our memories. The optimization problem for robust PCA was: $$ \\begin{equation*}\\begin{aligned} & \\min_{L} & & \\|L\\|_* + \\lambda\\|S\\|_1 \\\\ & \\text{subject to} & & L + S = M \\\\\\end{aligned}\\end{equation*} $$ Then we can make following analogies: $$ \\begin{aligned} f(L) &= \\|L\\|_* \\\\ g(S) &= \\|S\\|_1 \\\\ A &= I \\\\ B &= I \\\\ C &= M \\\\ \\end{aligned} $$ I'm sorry about the change of notation here but I feel that's the best way. What about minimization steps? I won't go into the details of their derivation but I hope to point you in the right direction if you want to do it on your own. $$ \\begin{aligned} L&#94;{k+1} &= \\underset{L}{\\mathrm{argmin}}\\mathcal{L}(L, S&#94;k, Y&#94;k) \\\\ & =\\|L\\|_* + \\langle Y&#94;k,M-L-S\\rangle + \\frac{\\mu_k}{2}\\|M-L-S\\|_F&#94;2 \\\\ & \\propto (1/\\mu_k)\\|L\\|_* + \\|M-S&#94;k+Y&#94;k/\\mu&#94;k\\|_F&#94;2 \\\\ & = \\mathcal{D}_{1\\mathbin{/}\\mu_k}(M-S&#94;k+Y&#94;k/\\mu&#94;k) \\end{aligned} $$ where \\(\\mathcal{D}_{1\\mathbin{/}\\mu_k}\\) is the singular value thresholding operator. Please refer to Section 2.1 of Cai et al. for detailed explanation of it. Then $$ \\begin{aligned} S&#94;{k+1} &= \\underset{S}{\\mathrm{argmin}}\\mathcal{L}(L&#94;{k+1}, S, Y&#94;k) \\\\ &= \\lambda\\|S\\|_1 + \\langle Y&#94;k,M-L-S\\rangle + \\frac{\\mu_k}{2}\\|M-L-S\\|_F&#94;2 \\\\ &\\propto (\\lambda/\\mu_k)\\|S\\|_1 + \\|X-L-Y&#94;k/\\mu&#94;k\\|_F&#94;2 \\\\ &= \\mathcal{P}_{(\\lambda/\\mu_k)}(X-L-Y&#94;k/\\mu&#94;k) \\end{aligned} $$ where \\(\\mathcal{P}_{1\\mathbin{/}\\mu_k}\\) is the soft thresholding operator. Section 6.5.2 of Boyd et al. is a good reference for the soft thresholding operator. It is commonly used to solve lasso regression. It is also a subroutine of the singular value thresholding operator. Implementation in Python with Numpy Now that we have all the steps ready, we can start implementing. We will only need a Python environment with version 3.6+ (just because I like static type hinting feature) and numpy. You can easily set this up with conda or Pipenv. 1 2 import numpy as np import numpy.linalg as la Let's first start by defining the proximal operators: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def soft_thresholding ( y : np . ndarray , mu : float ): \"\"\" Soft thresholding operator as explained in Section 6.5.2 of https://web.stanford.edu/~boyd/papers/pdf/prox_algs.pdf Solves the following problem: argmin_x (1/2)*||x-y||_F&#94;2 + lmb*||x||_1 Parameters ---------- y : np.ndarray Target vector/matrix lmb : float Penalty parameter Returns ------- x : np.ndarray argmin solution \"\"\" return np . sign ( y ) * np . clip ( np . abs ( y ) - mu , a_min = 0 , a_max = None ) def svd_shrinkage ( y : np . ndarray , tau : float ): \"\"\" SVD shrinakge operator as explained in Theorem 2.1 of https://statweb.stanford.edu/~candes/papers/SVT.pdf Solves the following problem: argmin_x (1/2)*||x-y||_F&#94;2 + tau*||x||_* Parameters ---------- y : np.ndarray Target vector/matrix tau : float Penalty parameter Returns ------- x : np.ndarray argmin solution \"\"\" U , s , Vh = np . linalg . svd ( y , full_matrices = False ) s_t = soft_thresholding ( s , tau ) return U . dot ( np . diag ( s_t )) . dot ( Vh ) I want my API to follow a scikit-learn -like design so here's how it should like at the end: 1 2 rpca = RobustPCA ( lmb = 4e-3 , max_iter = 100 ) L , S = rpca . fit ( X ) The only difference is that .fit function doesn't normally return anything in scikit-learn but I want it to return the low-rank and sparse components for the sake of simplicity. Then I start building the class with my main method .fit . Starting with .fit gives me a good idea about what other parameters I have to initialize or what submethods I'll end up having to implement: 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def fit ( self , X : np . ndarray ): mu = self . mu_0_ Y = X / self . _J ( X , mu ) S = np . zeros_like ( X ) S_last = np . empty_like ( S ) for k in range ( self . max_iter_ ): # Solve argmin_L ||X - (L + S) + Y/mu||_F&#94;2 + (lmb/mu)*||L||_* L = svd_shrinkage ( X - S + Y / mu , 1 / mu ) # Solve argmin_S ||X - (L + S) + Y/mu||_F&#94;2 + (lmb/mu)*||S||_1 S_last = S . copy () S = soft_thresholding ( X - L + Y / mu , self . lmb_ / mu ) # Update dual variables Y <- Y + mu * (X - S - L) Y += mu * ( X - S - L ) r , h = self . _get_residuals ( X , S , L , S_last , mu ) # Check stopping cirteria tol_r , tol_h = self . _update_tols ( X , L , S , Y ) if r < tol_r and h < tol_h : break # Update mu mu = self . _update_mu ( mu , r , h ) return L , S The private methods I need, ._J , ._get_residuals , ._update_tols and ._update_mu are implemented as follows. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def _get_residuals ( X : np . ndarray , S : np . ndarray , L : np . ndarray , S_last : np . ndarray , mu : float ): primal_residual = la . norm ( X - S - L , ord = \"fro\" ) dual_residual = mu * la . norm ( S - S_last , ord = \"fro\" ) return primal_residual , dual_residual def _update_mu ( self , mu : float , r : float , h : float ): if r > self . tau_ * h : return mu * self . rho_ elif h > self . tau_ * r : return mu / self . rho_ else : return mu def _update_tols ( self , X , S , L , Y ): tol_primal = self . tol_rel_ * max ( la . norm ( X ), la . norm ( S ), la . norm ( L )) tol_dual = self . tol_rel_ * la . norm ( Y ) return tol_primal , tol_dual def _J ( self , X : np . ndarray , lmb : float ): return max ( np . linalg . norm ( X ), np . max ( np . abs ( X )) / lmb ) We haven't talked about ._J . It's a dual variable initialization technqiue discussed in Section 3.1 of Lin et al. . The last part is to write an __init__ function, add some docstrings and wrap everything up in a class. 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 class RobustPCA : \"\"\" Solves robust PCA using Inexact ALM as explained in Algorithm 5 of https://arxiv.org/pdf/1009.5055.pdf Parameters ---------- lmb: penalty on sparse errors mu_0: initial lagrangian penalty rho: learning rate tau: mu update criterion parameter max_iter: max number of iterations for the algorithm to run tol_rel: relative tolerance \"\"\" def __init__ ( self , lmb : float , mu_0 : float = 1e-5 , rho : float = 2 , tau : float = 10 , max_iter : int = 10 , tol_rel : float = 1e-3 ): assert mu_0 > 0 assert lmb > 0 assert rho > 1 assert tau > 1 assert max_iter > 0 assert tol_rel > 0 self . mu_0_ = mu_0 self . lmb_ = lmb self . rho_ = rho self . tau_ = tau self . max_iter_ = max_iter self . tol_rel_ = tol_rel def fit ( self , X : np . ndarray ): \"\"\" Fits robust PCA to X and returns the low-rank and sparse components Parameters ---------- X: Original data matrix Returns ------- L: Low rank component of X S: Sparse error component of X \"\"\" assert X . ndim == 2 mu = self . mu_0_ Y = X / self . _J ( X , mu ) S = np . zeros_like ( X ) S_last = np . empty_like ( S ) for k in range ( self . max_iter_ ): # Solve argmin_L ||X - (L + S) + Y/mu||_F&#94;2 + (lmb/mu)*||L||_* L = svd_shrinkage ( X - S + Y / mu , 1 / mu ) # Solve argmin_S ||X - (L + S) + Y/mu||_F&#94;2 + (lmb/mu)*||S||_1 S_last = S . copy () S = soft_thresholding ( X - L + Y / mu , self . lmb_ / mu ) # Update dual variables Y <- Y + mu * (X - S - L) Y += mu * ( X - S - L ) r , h = self . _get_residuals ( X , S , L , S_last , mu ) # Check stopping cirteria tol_r , tol_h = self . _update_tols ( X , L , S , Y ) if r < tol_r and h < tol_h : break # Update mu mu = self . _update_mu ( mu , r , h ) return L , S def _J ( self , X : np . ndarray , lmb : float ): \"\"\" The function J() required for initialization of dual variables as advised in Section 3.1 of https://people.eecs.berkeley.edu/~yima/matrix-rank/Files/rpca_algorithms.pdf \"\"\" return max ( np . linalg . norm ( X ), np . max ( np . abs ( X )) / lmb ) @staticmethod def _get_residuals ( X : np . ndarray , S : np . ndarray , L : np . ndarray , S_last : np . ndarray , mu : float ): primal_residual = la . norm ( X - S - L , ord = \"fro\" ) dual_residual = mu * la . norm ( S - S_last , ord = \"fro\" ) return primal_residual , dual_residual def _update_mu ( self , mu : float , r : float , h : float ): if r > self . tau_ * h : return mu * self . rho_ elif h > self . tau_ * r : return mu / self . rho_ else : return mu def _update_tols ( self , X , S , L , Y ): tol_primal = self . tol_rel_ * max ( la . norm ( X ), la . norm ( S ), la . norm ( L )) tol_dual = self . tol_rel_ * la . norm ( Y ) return tol_primal , tol_dual Complexity Analysis All the norms and matrix additions/summations/multiplications are elementwise operations so that they're \\(\\mathcal{O}(np)\\) given that our matrix \\(X\\) is an \\(n\\times p\\) matrix. The major bottleneck of algorithms involving nuclear norm is that they typically require singular value thresholding which reqiuires SVD . Since we're computing a skinny SVD , the complexity will be \\(\\mathcal{O}(np\\min(n,p))\\) . SVD also requires to fit the entire data into the memory so it's inefficient in that sense too. This can become a huge issue if you want to scale this algorithm and the literature has addressed this issue in certain ways which I hope to discuss in another post. Things to Try The algorithm is ready to use, but here are a few suggestions I have for you to play around with the code a little and interact with it: Plot the interplay of r , h and mu over iterations to see the tug-of-war I mentioned earlier in action. Take one frame and record its evolution over the course of the algorithm. Especially observe how the sparse component for that frame S[frame,:] changes over time. You can estimate the rank of L A very accesible dataset is the cropped Yale B dataset where you have faces of different people taken under various lighting conditions. Just pick one or two people and incldue all the illumination conditions they have to see if you can extract their clean face in the low-rank component. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"/blog/2019/08/28/implementing-robust-pca-in-python/"},{"url":"/blog/2019/08/01/from-pca-to-robust-pca/","title":"From PCA to Robust- PCA","tags":"research","text":"PCA is widely known by its geometric interpretation. That is, finding successive orthonormal vectors to project the data onto, such that the reprojected variance is kept at a maximum. Here is another way to look at PCA . Let's say you have a data matrix \\(M\\) . You believe that there exists a low-rank matrix \\(L\\) —whose rank is less than \\(r\\) — if some noise is stripped out of \\(M\\) . This can be formulated as an optimization problem, where you try to find a matrix \\(L\\) that gives you the best low-rank approximation of \\(M\\) . $$ \\begin{equation*} \\begin{aligned} & \\min_{L} & & \\|M -L\\|_F&#94;2\\\\ & \\text{subject to} & & rank(L) < r \\\\ \\end{aligned} \\end{equation*} $$ Note that low-rank translates into the fact that there are correlations among samples and/or features. This ties our story back to the geometric interpretation of PCA . The solution to this problem is outliend by the famous Eckart-Young-Mirsky theorem , and is well-implemented in commonly used machine learning packages such as scikit-learn . It's easy to solve whether you use SVD , as the original thorem suggests, or solving the eigenproblem of the covariance matrix of the data. Something we haven't talked about yet is the term \\(\\|M -L\\|_F&#94;2\\) . Why Frobenius norm? This basically represents your assumption on the noise that is present in your data \\(M\\) or how do you like to penalize it. If you are like me and prefer the probabilistic view of PCA , this means that you assume your data is corrupted with i.i.d. Gaussian noise. But what if it wasn't? Candes et al. raise this question in their 2011 paper . In their own words, if the data is grossly corrupted in sparse regions, then \\(\\|M -L\\|_F&#94;2\\) is not an appropriate objective anymore. Okay then, how about we change it to \\(\\|M -L\\|_1\\) ? On paper, this seems perfect but we don't have the Eckart-Young-Mirsky theorem for this case. Let's take a step forward and don't make any assumptions on what rank \\(r\\) will be, but rather just try to minimize it as much as we can. While doing so, let's also make sure a high-fidelity low-rank approximation via minimizing \\(\\|S\\|_1\\) which represents entry-wise deviations from the actual data. Obviously these two objectives are in a tradeoff, so we will represent our preference in between the two via a regularizing parameter \\(\\lambda\\) . Here is the new objective function. $$ \\begin{equation*} \\begin{aligned} & \\min_{L} & & rank(L) + \\lambda\\|S\\|_1 \\\\ & \\text{subject to} & & L + S = M \\\\ \\end{aligned} \\end{equation*} $$ Rank minimization over a convex set is an NP -hard problem therefore it's not practical. What Candes et al. suggests is to replace \\(rank(L)\\) with \\(\\|L\\|_*\\) which is the nuclear norm of \\(L\\) . Nuclear norm is the convex envelope for the rank minimization problem, thus the bext convex approximation. In order to see why this is, let's first formally define rank of a matrix as \\(rank(L) = \\|\\sigma(L)\\|_0\\) . \\(\\sigma(L)\\) is the vector of singular values of \\(L\\) . A refresher, the 0-\"norm\" (in quotation marks because it's not really a norm) is simply the number of non-zero elements in a vector. Nuclear norm uses the 1-norm, which is the tightest convex relaxation of the 0-\"norm\", \\(\\|L\\|_* = \\|\\sigma(L)\\|_1\\) . It is very useful in practice, and as we'll see in other posts, opens up a plethora of applications where the eventual goal is to find a low-rank approximation of the data at hand. Consequently, our minimaztion problem becomes a convex optimization problem: $$ \\begin{equation*} \\begin{aligned} & \\min_{L} & & \\|L\\|_* + \\lambda\\|S\\|_1 \\\\ & \\text{subject to} & & L + S = M \\\\\\end{aligned}\\end{equation*} $$ This problem defines what we call today, robust PCA . It can be solved efficiently via Alternating Direction Method of Multipliers ( ADMM ). We saved the best question to the last: why would you want to use robust PCA for? While there are many applications one can think of, I find background-foreground separation in video surveillance to be the easiest to imagine. If frames captured by our camera is stored in a matrix \\(M\\) (frames by pixels), then \\(L\\) is the medium the camera looks at, background . It is low-rank since over many frames, the background stays the same and thus we have correlation among frames (also possibly among pixels as it is common in images). Sparse errors \\(S\\) then becomes moving objects, or the foreground . Robust PCA in Action Here is a royalty free airport camera footage I grabbed from YouTube. It fits my definition above, since the camera is fixed at a location and it doesn't rotate around. There are a few sparse objects moving around. By applying robust PCA , I could easily separate background from the moving object (in this case, the truck and a couple of planes to the very right of the frame through the end of the video). Had we have done it with PCA ? Well… I guess it's good for making viral ghost footage videos. if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) { var align = \"center\", indent = \"0em\", linebreak = \"false\"; if (false) { align = (screen.width < 768) ? \"left\" : align; indent = (screen.width < 768) ? \"0em\" : indent; linebreak = (screen.width < 768) ? 'true' : linebreak; } var mathjaxscript = document.createElement('script'); mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#'; mathjaxscript.type = 'text/javascript'; mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML'; var configscript = document.createElement('script'); configscript.type = 'text/x-mathjax-config'; configscript[(window.opera ? \"innerHTML\" : \"text\")] = \"MathJax.Hub.Config({\" + \" config: ['MMLorHTML.js'],\" + \" TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } },\" + \" jax: ['input/TeX','input/MathML','output/HTML-CSS'],\" + \" extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js'],\" + \" displayAlign: '\"+ align +\"',\" + \" displayIndent: '\"+ indent +\"',\" + \" showMathMenu: true,\" + \" messageStyle: 'normal',\" + \" tex2jax: { \" + \" inlineMath: [ ['\\\\\\\\(','\\\\\\\\)'] ], \" + \" displayMath: [ ['$$','$$'] ],\" + \" processEscapes: true,\" + \" preview: 'TeX',\" + \" }, \" + \" 'HTML-CSS': { \" + \" availableFonts: ['STIX', 'TeX'],\" + \" preferredFont: 'STIX',\" + \" styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} },\" + \" linebreaks: { automatic: \"+ linebreak +\", width: '90% container' },\" + \" }, \" + \"}); \" + \"if ('default' !== 'default') {\" + \"MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {\" + \"var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;\" + \"VARIANT['normal'].fonts.unshift('MathJax_default');\" + \"VARIANT['bold'].fonts.unshift('MathJax_default-bold');\" + \"VARIANT['italic'].fonts.unshift('MathJax_default-italic');\" + \"VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');\" + \"});\" + \"}\"; (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript); (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript); }","loc":"/blog/2019/08/01/from-pca-to-robust-pca/"}]};